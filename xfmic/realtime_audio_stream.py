#!/usr/bin/env python3
"""
å®æ—¶éŸ³é¢‘æµè·å–ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä»USBå£°å¡å®æ—¶è·å–éŸ³é¢‘æµå¹¶å¤„ç†
"""

import sys
import numpy as np
import pyaudio
import queue
import threading
import time
from collections import deque


class RealtimeAudioStream:
    """å®æ—¶éŸ³é¢‘æµå¤„ç†å™¨"""

    def __init__(self, device_index=None, rate=16000, chunk=1024):
        """
        åˆå§‹åŒ–

        Args:
            device_index: éŸ³é¢‘è®¾å¤‡ç´¢å¼•ï¼ˆUSBå£°å¡ï¼‰
            rate: é‡‡æ ·ç‡ (Hz)
            chunk: ç¼“å†²åŒºå¤§å°ï¼ˆé‡‡æ ·ç‚¹æ•°ï¼‰
        """
        self.device_index = device_index
        self.rate = rate
        self.chunk = chunk
        self.format = pyaudio.paInt16
        self.channels = 1

        self.p = pyaudio.PyAudio()
        self.stream = None
        self.is_running = False

        # éŸ³é¢‘æ•°æ®é˜Ÿåˆ—
        self.audio_queue = queue.Queue()

        # éŸ³é¢‘ç¼“å†²åŒºï¼ˆç”¨äºVADç­‰éœ€è¦å†å²æ•°æ®çš„åœºæ™¯ï¼‰
        self.buffer = deque(maxlen=int(rate * 2))  # ä¿ç•™2ç§’å†å²æ•°æ®

    def start(self):
        """å¯åŠ¨éŸ³é¢‘æµ"""
        if self.is_running:
            print("éŸ³é¢‘æµå·²åœ¨è¿è¡Œ")
            return

        try:
            self.stream = self.p.open(
                format=self.format,
                channels=self.channels,
                rate=self.rate,
                input=True,
                input_device_index=self.device_index,
                frames_per_buffer=self.chunk,
                stream_callback=self._audio_callback
            )

            self.is_running = True
            self.stream.start_stream()
            print(f"âœ“ éŸ³é¢‘æµå·²å¯åŠ¨ (è®¾å¤‡:{self.device_index}, é‡‡æ ·ç‡:{self.rate}Hz)")

        except Exception as e:
            print(f"âœ— å¯åŠ¨éŸ³é¢‘æµå¤±è´¥: {e}")
            raise

    def stop(self):
        """åœæ­¢éŸ³é¢‘æµ"""
        if not self.is_running:
            return

        self.is_running = False

        if self.stream:
            self.stream.stop_stream()
            self.stream.close()

        print("âœ“ éŸ³é¢‘æµå·²åœæ­¢")

    def _audio_callback(self, in_data, frame_count, time_info, status):
        """
        PyAudioéŸ³é¢‘å›è°ƒå‡½æ•°ï¼ˆå†…éƒ¨ä½¿ç”¨ï¼‰
        åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­è¢«è°ƒç”¨
        """
        # å°†åŸå§‹å­—èŠ‚æ•°æ®è½¬ä¸ºnumpyæ•°ç»„
        audio_data = np.frombuffer(in_data, dtype=np.int16)

        # æ”¾å…¥é˜Ÿåˆ—ä¾›ä¸»çº¿ç¨‹å¤„ç†
        self.audio_queue.put(audio_data)

        # æ·»åŠ åˆ°ç¼“å†²åŒº
        self.buffer.extend(audio_data)

        return (in_data, pyaudio.paContinue)

    def get_audio_chunk(self, timeout=1):
        """
        è·å–ä¸€ä¸ªéŸ³é¢‘æ•°æ®å—

        Args:
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

        Returns:
            numpyæ•°ç»„ï¼Œå¦‚æœè¶…æ—¶è¿”å›None
        """
        try:
            return self.audio_queue.get(timeout=timeout)
        except queue.Empty:
            return None

    def get_buffer_data(self):
        """
        è·å–ç¼“å†²åŒºçš„æ‰€æœ‰å†å²æ•°æ®

        Returns:
            numpyæ•°ç»„
        """
        return np.array(list(self.buffer))

    def close(self):
        """å…³é—­éŸ³é¢‘æµ"""
        self.stop()
        self.p.terminate()


# ==================== åº”ç”¨ç¤ºä¾‹ ====================

def example_1_basic_streaming():
    """ç¤ºä¾‹1: åŸºæœ¬éŸ³é¢‘æµç›‘å¬"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹1: åŸºæœ¬éŸ³é¢‘æµç›‘å¬")
    print("="*60)

    # åˆ›å»ºéŸ³é¢‘æµ
    stream = RealtimeAudioStream(device_index=1, rate=16000)

    try:
        stream.start()
        print("\nå¼€å§‹ç›‘å¬éŸ³é¢‘æµ...")
        print("æŒ‰ Ctrl+C åœæ­¢\n")

        while True:
            # è·å–éŸ³é¢‘æ•°æ®
            audio_chunk = stream.get_audio_chunk(timeout=1)

            if audio_chunk is not None:
                # è®¡ç®—éŸ³é‡
                volume = np.abs(audio_chunk).mean()
                max_value = np.max(np.abs(audio_chunk))

                # æ˜¾ç¤ºéŸ³é‡æ¡
                bar_length = int(volume / 100)
                bar = 'â–ˆ' * bar_length + 'â–‘' * (50 - bar_length)

                print(f"\réŸ³é‡: [{bar}] {volume:.0f} (å³°å€¼:{max_value})",
                      end='', flush=True)

    except KeyboardInterrupt:
        print("\n\nåœæ­¢ç›‘å¬")
    finally:
        stream.close()


def example_2_vad_detection():
    """ç¤ºä¾‹2: è¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼ˆVADï¼‰"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹2: è¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼ˆVADï¼‰")
    print("="*60)

    stream = RealtimeAudioStream(device_index=1, rate=16000)

    # VADå‚æ•°
    SPEECH_THRESHOLD = 500  # è¯­éŸ³éŸ³é‡é˜ˆå€¼
    SILENCE_DURATION = 1.0  # é™éŸ³æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰

    is_speaking = False
    silence_start = None
    speech_buffer = []

    try:
        stream.start()
        print("\nå¼€å§‹æ£€æµ‹è¯­éŸ³æ´»åŠ¨...")
        print("è¯·è¯´è¯æµ‹è¯•...\n")

        while True:
            audio_chunk = stream.get_audio_chunk(timeout=1)

            if audio_chunk is not None:
                volume = np.abs(audio_chunk).mean()

                # æ£€æµ‹è¯­éŸ³å¼€å§‹
                if not is_speaking and volume > SPEECH_THRESHOLD:
                    is_speaking = True
                    silence_start = None
                    speech_buffer = [audio_chunk]
                    print("\nğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹...")

                # è¯­éŸ³è¿›è¡Œä¸­
                elif is_speaking and volume > SPEECH_THRESHOLD:
                    silence_start = None
                    speech_buffer.append(audio_chunk)

                # æ£€æµ‹é™éŸ³
                elif is_speaking and volume <= SPEECH_THRESHOLD:
                    if silence_start is None:
                        silence_start = time.time()

                    speech_buffer.append(audio_chunk)

                    # é™éŸ³è¶…è¿‡é˜ˆå€¼ï¼Œåˆ¤å®šè¯­éŸ³ç»“æŸ
                    if time.time() - silence_start > SILENCE_DURATION:
                        print(f"âœ“ è¯­éŸ³ç»“æŸ (æ—¶é•¿: {len(speech_buffer) * 0.064:.1f}ç§’)")

                        # åˆå¹¶æ‰€æœ‰éŸ³é¢‘æ•°æ®
                        full_audio = np.concatenate(speech_buffer)

                        # è¿™é‡Œå¯ä»¥ï¼š
                        # 1. ä¿å­˜ä¸ºæ–‡ä»¶
                        # 2. å‘é€åˆ°ASR
                        # 3. è¿›è¡Œå…¶ä»–å¤„ç†
                        print(f"   å…±é‡‡é›† {len(full_audio)} ä¸ªé‡‡æ ·ç‚¹")

                        # é‡ç½®
                        is_speaking = False
                        silence_start = None
                        speech_buffer = []
                        print("\nç­‰å¾…ä¸‹ä¸€æ¬¡è¯­éŸ³...\n")

                # æ˜¾ç¤ºçŠ¶æ€
                status = "ğŸ”´ è¯­éŸ³ä¸­" if is_speaking else "âšª é™éŸ³"
                print(f"\r{status}  éŸ³é‡: {volume:.0f}  ", end='', flush=True)

    except KeyboardInterrupt:
        print("\n\nåœæ­¢æ£€æµ‹")
    finally:
        stream.close()


def example_3_realtime_asr():
    """ç¤ºä¾‹3: å®æ—¶ASRé›†æˆï¼ˆæ¨¡æ‹Ÿï¼‰"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹3: å®æ—¶ASRé›†æˆ")
    print("="*60)

    from rk3328_controller import RK3328Controller

    stream = RealtimeAudioStream(device_index=1, rate=16000)
    controller = RK3328Controller('/dev/ttyUSB0')

    if not controller.connect():
        print("ä¸²å£è¿æ¥å¤±è´¥")
        return

    is_recording = False
    recording_buffer = []

    try:
        stream.start()
        print("\nâœ“ ç³»ç»Ÿå°±ç»ª")
        print("æµç¨‹: ç­‰å¾…å”¤é†’ â†’ å®æ—¶å½•éŸ³ â†’ å‘é€ASR\n")

        # å¯åŠ¨éŸ³é¢‘å¤„ç†çº¿ç¨‹
        def audio_processor():
            while stream.is_running:
                audio_chunk = stream.get_audio_chunk(timeout=0.1)

                if audio_chunk is not None and is_recording:
                    recording_buffer.append(audio_chunk)

                    # æ¯éš”0.5ç§’å¯ä»¥å‘é€ä¸€æ¬¡åˆ°å®æ—¶ASR
                    if len(recording_buffer) % 8 == 0:  # çº¦0.5ç§’
                        # æ¨¡æ‹Ÿå‘é€åˆ°å®æ—¶ASR
                        audio_segment = np.concatenate(recording_buffer[-8:])
                        print(f"\râ†’ å‘é€éŸ³é¢‘åˆ°ASR ({len(audio_segment)}é‡‡æ ·ç‚¹)",
                              end='', flush=True)

                        # è¿™é‡Œè°ƒç”¨å®æ—¶ASR API
                        # result = realtime_asr_api.send(audio_segment)

        threading.Thread(target=audio_processor, daemon=True).start()

        while True:
            # ç›‘å¬å”¤é†’äº‹ä»¶
            msg = controller.read_device_message(timeout=1)

            if msg and msg.get('type') == 'wakeup':
                angle = msg['content']['angle']
                print(f"\nğŸ¤ å”¤é†’æ£€æµ‹ (æ–¹å‘: {angle}Â°)")
                print("å¼€å§‹å®æ—¶å½•éŸ³ï¼Œè¯·è¯´è¯...")

                is_recording = True
                recording_buffer = []

                # å½•éŸ³5ç§’
                time.sleep(5)

                is_recording = False

                # å¤„ç†å®Œæ•´å½•éŸ³
                if recording_buffer:
                    full_audio = np.concatenate(recording_buffer)
                    print(f"\nâœ“ å½•éŸ³å®Œæˆ (æ—¶é•¿: {len(full_audio)/16000:.1f}ç§’)")
                    print("â†’ å‘é€å®Œæ•´éŸ³é¢‘åˆ°ASR...")

                    # è¿™é‡Œè°ƒç”¨ASR API
                    # result = asr_api.recognize(full_audio)
                    # print(f"è¯†åˆ«ç»“æœ: {result}")

                    print("\nç­‰å¾…ä¸‹ä¸€æ¬¡å”¤é†’...\n")

    except KeyboardInterrupt:
        print("\n\nç¨‹åºé€€å‡º")
    finally:
        stream.close()
        controller.close()


def example_4_audio_analysis():
    """ç¤ºä¾‹4: å®æ—¶éŸ³é¢‘åˆ†æ"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹4: å®æ—¶éŸ³é¢‘åˆ†æ")
    print("="*60)

    stream = RealtimeAudioStream(device_index=1, rate=16000, chunk=2048)

    try:
        stream.start()
        print("\nå¼€å§‹éŸ³é¢‘åˆ†æ...")
        print("æ˜¾ç¤º: éŸ³é‡ | è¿‡é›¶ç‡ | é¢‘è°±èƒ½é‡\n")

        while True:
            audio_chunk = stream.get_audio_chunk(timeout=1)

            if audio_chunk is not None:
                # 1. éŸ³é‡
                volume = np.abs(audio_chunk).mean()

                # 2. è¿‡é›¶ç‡ï¼ˆZero Crossing Rateï¼‰
                # ç”¨äºåŒºåˆ†è¯­éŸ³å’Œå™ªéŸ³
                zero_crossings = np.sum(np.abs(np.diff(np.sign(audio_chunk))))
                zcr = zero_crossings / len(audio_chunk)

                # 3. é¢‘è°±èƒ½é‡
                fft = np.fft.fft(audio_chunk)
                spectrum_energy = np.abs(fft[:len(fft)//2]).mean()

                # æ˜¾ç¤º
                print(f"\réŸ³é‡:{volume:6.0f} | è¿‡é›¶ç‡:{zcr:.3f} | "
                      f"é¢‘è°±:{spectrum_energy:6.0f}  ",
                      end='', flush=True)

    except KeyboardInterrupt:
        print("\n\nåœæ­¢åˆ†æ")
    finally:
        stream.close()


def main():
    """ä¸»å‡½æ•°"""
    print("="*60)
    print("å®æ—¶éŸ³é¢‘æµè·å–ç¤ºä¾‹")
    print("="*60)

    print("\nè¯·é€‰æ‹©ç¤ºä¾‹:")
    print("  1. åŸºæœ¬éŸ³é¢‘æµç›‘å¬")
    print("  2. è¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼ˆVADï¼‰")
    print("  3. å®æ—¶ASRé›†æˆ")
    print("  4. å®æ—¶éŸ³é¢‘åˆ†æ")

    choice = input("\nè¯·é€‰æ‹© (1-4): ").strip()

    if choice == '1':
        example_1_basic_streaming()
    elif choice == '2':
        example_2_vad_detection()
    elif choice == '3':
        example_3_realtime_asr()
    elif choice == '4':
        example_4_audio_analysis()
    else:
        print("æ— æ•ˆé€‰æ‹©")


if __name__ == '__main__':
    main()
